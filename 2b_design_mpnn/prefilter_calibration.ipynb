{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c19dd31-8068-4555-8866-95421412db48",
   "metadata": {},
   "source": [
    "# This notebook contains the pipeline for setting up MPNN prefilters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a2f742-beee-4f73-9cd3-ffb7029ea83f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 0: Imports and Variable Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e054d-acb3-41a2-8d4c-df2b965364a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f998bbf-f072-49cb-9ef7-36754ab3006f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### DESIGN-00\n",
    "\n",
    "###################################\n",
    "#### Same as rifdock notebook #####\n",
    "###################################\n",
    "# Utilities\n",
    "import sys, os, time, glob, random, shutil, subprocess, math\n",
    "\n",
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# string is a utility library which contains some useful string constants. For instance, string.digits == '0123456789'\n",
    "import string\n",
    "\n",
    "# re is a module that enables the use of \"regular expressions,\" a common format for matching strings to patterns\n",
    "import re\n",
    "\n",
    "# matplotlib, with its submodule pyplot (or plt), is a popular tool for plotting data and making publication-quality graphs.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seaborn, commonly abbreviated as sns, is a library used to make publication-quality plots with lots of options; it is built on top of matplotlib.\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn, aka sci-kit learn, is a library for simple machine learning in python. We use it for a few statistical calculations.\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# scipy is a general science module for python with many useful statistical tools. We use it to fit curves to data\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Functions written by Chris Norn / Cameron for maximum likelihood fitting are stored in this module\n",
    "from maximum_likelihood import *\n",
    "\n",
    "# Pyrosetta is the python-based interface for running Rosetta for protein modeling and design\n",
    "import pyrosetta\n",
    "from pyrosetta import *\n",
    "from pyrosetta.rosetta import *\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "\n",
    "# This last bit is here to prevent certain functions from returning a bunch of warnings we don't care about\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9148a32b-acea-4772-b5d0-2560f167f457",
   "metadata": {
    "tags": []
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------<br>\n",
    "This cell collects the outputs from the \"predictor\" script and saves it all to a single `.csv` (per target DNA) <br>\n",
    "NOTE: this cell takes a few minutes to run, due to pandas inefficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb830468-5560-418a-913c-1f4270434f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-01\n",
    "\n",
    "output_path = f'prefilter.csv'\n",
    "\n",
    "\n",
    "# Collect the paths to all output .csv files\n",
    "csv_fs = glob.glob(f'{path_to_prefilter_calibration_outputs}/*.csv')\n",
    "\n",
    "# load a dataframe\n",
    "df = pd.concat([pd.read_csv(f) for f in csv_fs], sort=False)\n",
    "\n",
    "# Then save the DataFrame to a csv\n",
    "df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffaf746-0fd9-4827-9c59-1f85871eb057",
   "metadata": {
    "tags": []
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------<br>\n",
    "This cell loads in the outputs from the previous cell and filters out very bad results from the dataset so they don't skew the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a43e90-d741-43af-957c-b7b34f432b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-02\n",
    "\n",
    "# Read in the DataFram from where we saved it\n",
    "df = pd.read_csv(f'prefilter.csv')\n",
    "\n",
    "\n",
    "# Filter only for cases with negative ddg\n",
    "# ddg is the change in Gibbs free energy of binding between protein and DNA (as computed by Rosetta)\n",
    "# This notation selects only the rows of a DataFrame for which the [bracketed] statement evaluates to True\n",
    "df = df[ df['ddg'] < 0 ]\n",
    "\n",
    "\n",
    "# Filter also for contact molecular surface > 10\n",
    "# This metric measures the surface area along which the protein and DNA are in contact with each other\n",
    "df = df[ df['contact_molecular_surface'] > 10 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6ae3dc-5fb4-4d41-9b15-38e4c2af0729",
   "metadata": {
    "tags": []
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------<br>\n",
    "This cell splits the data into \"predictor\" and \"pilot\" <br>\n",
    "The \"predictor\" data have only fast metrics. <br>\n",
    "The \"pilot\" data have both the fast and slow metrics, which are actually the same score terms with one key difference: <br>\n",
    "&emsp; \"pilot\" examples were run through a Rosetta \"relax\" protocol, which moves the protein backbone and sidechains to minimize free energy. <br>\n",
    "We will try to predict whether the pilot data pass the full filters based on their fast metrics only. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45f315-0ea6-4032-8606-5e2a80efc250",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-03\n",
    "\n",
    "# Define a function that can add a suffix to the names of the columns in a DataFrame\n",
    "# For instance, a column named \"FOO\" could become \"FOO_bar\"\n",
    "# This is useful for combining two dataframes with the same column names, such as our \"predictor\" and \"pilot\" data\n",
    "def suffix_all_columns(df, suffix):\n",
    "    cols = list(df.columns)\n",
    "    for i in range(len(cols)):\n",
    "        cols[i] = cols[i] + suffix\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "predictor_dfs = {}\n",
    "pilot_dfs = {}\n",
    "    \n",
    "# Divide the DataFrame into our two sets based on the value in the column 'is_prefilter', which contains boolean values\n",
    "predictor_df = df[   df['is_prefilter'] ]\n",
    "pilot_df     = df[ ~ df['is_prefilter'] ]\n",
    "#                 ^^^ the ~ operator performs logical negation, element-wise on pandas objects\n",
    "\n",
    "# Add the \"_pred\" suffix to the column names of the predictor DataFrame\n",
    "predictor_df = suffix_all_columns(predictor_df, \"_pred\")\n",
    "\n",
    "# Restore the un-suffixed \"tag\" column\n",
    "predictor_df['tag'] = predictor_df['tag_pred']\n",
    "\n",
    "\n",
    "# Merge the predictor data back into the pilot dataframe\n",
    "pilot_df = pd.merge(pilot_df, predictor_df, how='inner', on='tag')\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(\"Length of predictor dataframe:\\t\", len(predictor_df))\n",
    "print(\"Length of pilot dataframe:\\t\", len(pilot_df))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70337533-ae82-4f9c-9181-27d78856e779",
   "metadata": {
    "tags": []
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------<br>\n",
    "This cell is now going to apply a specified set of filters to the dataset, using the available metrics. <br>\n",
    "Our goal is, essentially, to distinguish good docks/designs from bad ones based on the quality of the interface. <br>\n",
    "The key calculations we base this on are \"ddg\" and \"contact_molecular_surface\". <br>\n",
    "\n",
    "The aptly-named `contact_molecular_surface` (shorthand `cms`) is the surface area in which the protein contacts the target. <br>\n",
    "\n",
    "Because of inherent Lennard-Jones attraction between molecules, there is a bias for larger interfaces to also have lower `ddg`s. <br>\n",
    "To counteract this, we filter on the ratio between `ddg` and `cms`, which you can think of as the \"quality\" or \"density\" of the interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180af095-d598-4936-beb4-dee14e6d35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-04\n",
    "\n",
    "# The format for the dictionary of features for filtering is:\n",
    "#   'NAME_IN_PILOT_DF'           :  [ CUTOFF , KEEP_ABOVE , NAME_IN_PREDICTOR_DF , IS_INT],\n",
    "#      (string)                       (float)  (boolean)   (string)               (boolean)\n",
    "\n",
    "# For instance, the following would say that we should filter on the variable \"ddg\", \n",
    "#     which is called \"ddg_pred\" in the predictor DF, which is not a discrete variable (integer),\n",
    "#     and we should keep only cases with scores *below* -10 :\n",
    "example_dict = {\n",
    "    'ddg' :  [ -10  ,   False   , \"ddg_pred\" , False  ]\n",
    "}\n",
    "# and now we delete the example variable\n",
    "del example_dict\n",
    "\n",
    "# ...and here is the actual dictionary to use:\n",
    "terms_and_cuts = {\n",
    "    'ddg_over_cms'               :  [ -0.078 ,   False   , \"ddg_over_cms_pred\"              , False ],\n",
    "    'contact_molecular_surface'  :  [   225  ,    True   , \"contact_molecular_surface_pred\" , False ],\n",
    "}\n",
    "# This is one place you could play around with the numbers to see what happens, if you'd like\n",
    "\n",
    "\n",
    "# Next, we are going to actually apply our filters one by one and keep track of the pass-rates\n",
    "# If you see that a filter is removing 99.99% of designs or doing nothing, you may want to change your cutoffs.\n",
    "print('-------------------------------------------------')\n",
    "\n",
    "# Filter all the terms and print the thresholds\n",
    "ok_terms = []\n",
    "for pilot_term in terms_and_cuts:\n",
    "    cut, keep_high, term, is_int = terms_and_cuts[pilot_term]\n",
    "    ok_term = pilot_term + \"_ok\"\n",
    "    if ( keep_high ):\n",
    "        score_df[ok_term] = score_df[pilot_term] >= cut\n",
    "    else:\n",
    "        score_df[ok_term] = score_df[pilot_term] <= cut\n",
    "\n",
    "    ok_terms.append(ok_term)\n",
    "\n",
    "    print(\"%30s: %6.2f\"%(pilot_term, cut))\n",
    "\n",
    "# Print the pass rates for each term\n",
    "print()\n",
    "score_df['orderable'] = True\n",
    "for ok_term in ok_terms:\n",
    "    score_df['orderable'] = score_df['orderable'] & score_df[ok_term]\n",
    "    print(\"%30s: %5.0f%% pass-rate\"%(ok_term.replace(\"_ok\", \"\"), score_df[ok_term].sum() / len(score_df) * 100))\n",
    "\n",
    "# print the overall pass rate   \n",
    "print()\n",
    "print(\"%30s: %i   -- %.2f%%\"%('Passing', score_df['orderable'].sum(), (100*score_df['orderable'].sum() / len(score_df))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd5e1a-70a3-4ebc-b37d-58622d6e702d",
   "metadata": {
    "tags": []
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------<br>\n",
    "This cell is going to plot the distributions of our filter metrics in the pilot and predictor datasets. <br>\n",
    "The main take-away you should see is that the scores are better in the pilot dataset because of the Rosetta relax step. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a3fb2-9d2c-49ce-99c7-880a84ca5792",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-05\n",
    "\n",
    "# Get the names of metrics we care about from the filter dictionary\n",
    "relevant_features  = terms_and_cuts.keys()\n",
    "\n",
    "# Set up the axes we will be plotting on using matplotlib\n",
    "ncols = len(relevant_features)\n",
    "nrows = len(seqs)\n",
    "(fig, axs) = plt.subplots(\n",
    "    ncols=ncols, nrows=nrows, figsize=[6*ncols,3*nrows]\n",
    ")\n",
    "axs = axs.reshape(-1)\n",
    "\n",
    "# Make all of the plots\n",
    "i = 0\n",
    "\n",
    "for metric in terms_and_cuts:\n",
    "    metric_pred = terms_and_cuts[metric][2]\n",
    "\n",
    "    # seaborn's distplot essentially makes a histogram. \n",
    "    # It also plots the kernel density estimate (kde), which is sort of a smooth fit to the histogram\n",
    "    sns.distplot(pilot_dfs[seq][metric], ax=axs[i], color='blue', label='pilot')\n",
    "    sns.distplot(predictor_dfs[seq][metric_pred], ax=axs[i], color='orange', label='predictor')\n",
    "\n",
    "    # add legend and title\n",
    "    axs[i].legend()\n",
    "    axs[i].set_title(seq)\n",
    "\n",
    "    # keep track of which axis we are plotting on with a simple incrementor\n",
    "    i += 1\n",
    "\n",
    "# Format our plots for better readability / aesthetics\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9940729-443c-43bd-9c39-3506c388ae45",
   "metadata": {
    "tags": []
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------<br>\n",
    "Here, we want to look at some of the designs that are passing our filters and decide if they actually look good. <br>\n",
    "This cell will print out the tags for the passing designs into `tags.list`. <br>\n",
    "For now you'll need to work out where the actual corresponding pdbs are. (FIX THIS!) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035efaa0-3498-40a3-9ecc-a5522ddc28ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------<br>\n",
    "Next we are going to set up our pre-filter equation. <br>\n",
    "We will use this to decide which designs are worth running Rosetta relax (slow metrics) on. <br>\n",
    "The equation is fit by multiple-exponential regression. <br>\n",
    "The input variables are the \"fast\" metrics, which are the values of the features in the \"predictor\" dataset. <br>\n",
    "The output variable, which we are trying to predict, is the *probability that a corresponding pilot model would pass the full metrics* <br>\n",
    "<br>\n",
    "\n",
    "The result of this cell is an equation which is saved to a text file (`filter_eq_{seq}.txt`) so that we can use it later during the full-scale MPNN design step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0bfc3-c2fd-4691-ba91-9cee53f0d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-06\n",
    "\n",
    "print('-------------------------------------------------')\n",
    "\n",
    "train_df = pilot_df.copy()\n",
    "predictor_df = predictor_df.copy()\n",
    "\n",
    "all_indices = list(range(len(train_df)))\n",
    "test_indices = []\n",
    "\n",
    "# This sets up maximum likihood method\n",
    "_, prob_array, eqs = train_and_predict_mle(train_df, all_indices, test_indices, terms_and_cuts, \"predict\", predictor_df, True)\n",
    "\n",
    "print(\"\")\n",
    "print('- predictor_filters ' + \" , \".join( terms_and_cuts[x][2][:-5] for x in list(terms_and_cuts)))\n",
    "print('- equation = \"-' + \"*\".join(eqs) + '\"')\n",
    "with open(f'filter_eq.txt','w') as f_out:\n",
    "    f_out.write('\"-' + \"*\".join(eqs) + '\"\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0ca04-cb6f-40df-a38d-e07c002f7d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-07\n",
    "\n",
    "print('-------------------------------------------------')\n",
    "\n",
    "\n",
    "# Apply the mle method to the training set to get a feel for how well it worked\n",
    "apply_prob_arrays(score_df, prob_array, \"predict\")\n",
    "score_df['log_predict'] = np.log10(score_df['predict'])\n",
    "plot_df = score_df\n",
    "fpr,tpr,thresholds = roc_curve(plot_df[\"orderable\"], plot_df[\"predict\"])\n",
    "\n",
    "# Make the ROC plot\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'r', label = \"Predictor auc = %.2f\"%(auc(fpr, tpr)))\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Make the other plots\n",
    "\n",
    "# Make a cool graph to get a feel for where different predict values lie\n",
    "df_c=score_df.sort_values(\"predict\", ascending=False)\n",
    "df_c['total_orderable'] = df_c['orderable'].cumsum()\n",
    "df_c['log_predict'] = np.log10(df_c['predict'])\n",
    "\n",
    "\n",
    "cmap = sns.cubehelix_palette(as_cmap=True)\n",
    "\n",
    "lowb = np.percentile(df_c['log_predict'], 2)\n",
    "upb = np.percentile(df_c['log_predict'], 98)\n",
    "f, ax = plt.subplots(figsize=(7, 4))\n",
    "points = ax.scatter(range(len(df_c)), df_c['total_orderable'], c=df_c['log_predict'], vmin=lowb,vmax=upb, cmap=cmap)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "cb = f.colorbar(points)\n",
    "cb.set_label(\"log_predict\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "apply_prob_arrays(predictor_df, prob_arrays[seq], \"predict\")\n",
    "predictor_df['log_predict'] = np.log10(predictor_df['predict'])\n",
    "minimum = predictor_df['log_predict'].min()\n",
    "maximum = predictor_df['log_predict'].max()\n",
    "steps = 20\n",
    "step = (maximum - minimum)/steps\n",
    "probability_mapping_x = np.arange(minimum, maximum, step)\n",
    "probability_mapping_y = []\n",
    "\n",
    "last_prob = None\n",
    "for step_prob in probability_mapping_x:\n",
    "    upper = step_prob + step\n",
    "    total = score_df[(score_df['log_predict'] > step_prob) & (score_df['log_predict'] < upper)]\n",
    "    orderable = total['orderable'].sum()\n",
    "    if ( len(total) < 10 ):\n",
    "        prob = last_prob\n",
    "    else:\n",
    "        prob = orderable / len(total)\n",
    "    probability_mapping_y.append(prob)\n",
    "    last_prob = prob\n",
    "# fill in the beginning\n",
    "last_prob = probability_mapping_y[-1]\n",
    "for i in range(len(probability_mapping_y)):\n",
    "    i = len(probability_mapping_y) - i - 1\n",
    "    if ( probability_mapping_y[i] is None ):\n",
    "        probability_mapping_y[i] = last_prob\n",
    "    last_prob = probability_mapping_y[i]\n",
    "\n",
    "probability_mapping_y = np.array(probability_mapping_y)\n",
    "\n",
    "plt.xlabel(\"log_predict\")\n",
    "plt.ylabel(\"Pilot success rate\")\n",
    "plt.scatter(probability_mapping_x, probability_mapping_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8d96b5-ac68-446d-8da3-81b3ec23bc19",
   "metadata": {
    "tags": []
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------<br>\n",
    "Now we are going to apply our maximum likelihood equation (MLE) to the predictor dataset and see what happens. <br>\n",
    "For now, it's not important to understand the purpose of this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b95d6-077b-46ef-9994-d5a0dea9be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-08\n",
    "\n",
    "# Apply the mle to the predictor data and see how the values look\n",
    "    print('-------------------------------------------------')\n",
    "\n",
    "predictor_df = predictor_df.copy()\n",
    "\n",
    "apply_prob_arrays(predictor_df, prob_array, \"predict\")\n",
    "predictor_df['log_predict'] = np.log10(predictor_df['predict'])\n",
    "bounds = (np.percentile(predictor_df['log_predict'], 1), np.percentile(predictor_df['log_predict'], 99))\n",
    "sns.distplot(predictor_df['log_predict'].clip(bounds[0], bounds[1]))\n",
    "plt.title(\"All predicted data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37a1cce-833e-4c61-9bae-dbad359213e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------------<br>\n",
    "To actually use our maximum likelihood equation (MLE) as a filter, we need to decide a cutoff to use. <br>\n",
    "This cell will determine the cutoff by locating the 95th percentile of the scores. <br>\n",
    "We assume that the distribution will be similar in the full-scale design runs, so using this cutoff should result in a 5% pass-rate of the pre-filter. <br>\n",
    "The end result is a file (`filter_cut_{seq}.txt`) which contains the cutoff scores that we'll use during the full design step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc44be71-a16e-4efc-9f8b-69e327a65a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-09\n",
    "\n",
    "print('-------------------------------------------------')\n",
    "\n",
    "predictor_df = predictor_df.copy()\n",
    "\n",
    "apply_prob_arrays(predictor_df, prob_array, \"predict\")\n",
    "predictor_df['log_predict'] = np.log10(predictor_df['predict'])\n",
    "\n",
    "fraction_to_design = 0.05\n",
    "topXp = int(len(predictor_df)*fraction_to_design)\n",
    "MLE_cut = list(sorted(-predictor_df['log_predict']))[topXp]\n",
    "print(f'To predict for the top {fraction_to_design*100}% use an MLE cutoff > {-MLE_cut}')\n",
    "print(f'In your data set this corresponds to {topXp} successes out of {len(predictor_df)}')\n",
    "\n",
    "with open(f'{filter_cut.txt','w') as f_out:\n",
    "    f_out.write(str(-MLE_cut) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyRosetta",
   "language": "python",
   "name": "pyrosetta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
